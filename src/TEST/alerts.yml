# ==================== monitoring/prometheus/alerts.yml ====================
"""
groups:
  - name: bot_alerts
    interval: 30s
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: |
          (sum(rate(bot_errors_total[5m])) / sum(rate(bot_requests_total[5m]))) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} over the last 5 minutes"
      
      # Critical error rate
      - alert: CriticalErrorRate
        expr: |
          (sum(rate(bot_errors_total[5m])) / sum(rate(bot_requests_total[5m]))) > 0.10
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Critical error rate"
          description: "Error rate is {{ $value | humanizePercentage }} - immediate attention required"
      
      # Low cache hit rate
      - alert: LowCacheHitRate
        expr: |
          (sum(rate(bot_cache_hits_total[10m])) / 
           (sum(rate(bot_cache_hits_total[10m])) + sum(rate(bot_cache_misses_total[10m])))) < 0.5
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Cache hit rate below 50%"
          description: "Cache hit rate is {{ $value | humanizePercentage }}"
      
      # High queue size
      - alert: HighQueueSize
        expr: bot_queue_size{queue_name="downloads"} > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Download queue size high"
          description: "Queue size is {{ $value }} - may need more workers"
      
      # Database connection pool exhausted
      - alert: DatabasePoolExhausted
        expr: |
          (pg_stat_database_numbackends{datname="bot_db"} / 
           pg_settings_max_connections) > 0.8
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Database connection pool nearly exhausted"
          description: "{{ $value | humanizePercentage }} of connections in use"
      
      # High memory usage
      - alert: HighMemoryUsage
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value | humanizePercentage }}"
      
      # Disk space low
      - alert: DiskSpaceLow
        expr: |
          (node_filesystem_avail_bytes{mountpoint="/"} / 
           node_filesystem_size_bytes{mountpoint="/"}) < 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Disk space critically low"
          description: "Only {{ $value | humanizePercentage }} disk space remaining"
      
      # Service down
      - alert: ServiceDown
        expr: up{job=~"bot-api|celery-workers"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "{{ $labels.job }} has been down for more than 1 minute"
      
      # High response time
      - alert: HighResponseTime
        expr: |
          histogram_quantile(0.95, 
            rate(bot_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time"
          description: "95th percentile response time is {{ $value }}s"
      
      # Payment failures
      - alert: PaymentFailures
        expr: |
          sum(rate(bot_payment_failures_total[5m])) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Payment failures detected"
          description: "{{ $value }} payment failures per second"
"""